{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pyttsx3\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 50 #We'll be workign with 50 * 50 pixel images\n",
    "\n",
    "LABELS = ['A', 'C', 'E', 'H', 'I', 'L', 'O', 'U', 'V', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 120)\n",
    "engine.setProperty('voice',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"withbgmodelv_small_test.h5\"\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_PATH = \"data/train_data/A/A_bg_less2.jpg\"\n",
    "\n",
    "def preprocess_image(IMG_PATH):\n",
    "    \"\"\"\n",
    "    :param IMG_PATH: path of the image\n",
    "    :return: image array by preprocessing the image\n",
    "    Example:\n",
    "        img_array = preprocess_image(\"a.jpg\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if \"array\" not in str(type(IMG_PATH)): # taking image as input\n",
    "            img = cv2.imread(IMG_PATH)\n",
    "        else: img = IMG_PATH # taking numpy array of image as input\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Change color space to gray\n",
    "\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        img_array = img.reshape(IMAGE_SIZE, IMAGE_SIZE, 1) # Reshape array to l * w * channels\n",
    "\n",
    "        img_array = img_array / 255.0\n",
    "        \n",
    "        img_array = np.expand_dims(img_array, axis = 0) # Expand Dimension of the array as our model expects a 4D array\n",
    "\n",
    "        return img_array\n",
    "    \n",
    "    except Exception as e:\n",
    "        print (\"Unexpected error occured\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_letter(IMG_PATH):\n",
    "    \"\"\"\n",
    "    :param IMG_PATH: path of the image\n",
    "    :return: confident_percent, predicted label using the model or None if exception occurs\n",
    "    eg:\n",
    "        print(which_letter(\"sample.jpeg\"))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_array = preprocess_image(IMG_PATH)\n",
    "        preds= model.predict(img_array)\n",
    "        preds *= 100\n",
    "        most_likely_class_index = int(np.argmax(preds))\n",
    "        return preds.max(), LABELS[most_likely_class_index]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        return None\n",
    "    \n",
    "# conf, label = which_letter(IMG_PATH)\n",
    "# print (\"The predicted letter is {} with {} % confidence.\".format(label,conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted letter is A with 99.99952697753906 % confidence.\n"
     ]
    }
   ],
   "source": [
    "IMG_PATH = \"data/train_data/A/A_bg_less2.jpg\"\n",
    "\n",
    "conf, label = which_letter(IMG_PATH)\n",
    "print (\"The predicted letter is {} with {} % confidence.\".format(label,conf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Frames from Webcam and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"Speech Assistant\"\n",
    "frame_height, frame_width, roi_height, roi_width = 1200,1800,400,400\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)\n",
    "x_start, y_start = 200,200\n",
    "sentence = \"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret is None:\n",
    "        print (\"No frame captured\")\n",
    "        continue\n",
    "        \n",
    "    # bounding box which captures ASL sign to be detected by the system\n",
    "    cv2.rectangle(frame, (x_start, y_start), (x_start+roi_width, y_start+roi_height), (255,0,0),3)\n",
    "    \n",
    "    # Crop blue rectangular area(ROI)\n",
    "    img1 = frame[y_start: y_start + roi_height, x_start: x_start+roi_width]\n",
    "    \n",
    "    img_ycrcb = cv2.cvtColor(img1, cv2.COLOR_BGR2YCR_CB)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(img_ycrcb, (11,11),0)\n",
    "    \n",
    "    # lower  and upper skin color\n",
    "    skin_ycrcb_min = np.array((0,138,67))\n",
    "    skin_ycrcb_max = np.array((255,173,133))\n",
    "    \n",
    "    # detecting the hand in the bounding box    \n",
    "    mask = cv2.inRange(blur, skin_ycrcb_min, skin_ycrcb_max)\n",
    "    \n",
    "    kernel = np.ones((2,2), dtype = np.uint8)\n",
    "    \n",
    "    # Fixes holes in foreground    \n",
    "    mask = cv2.dilate(mask, kernel, iterations = 1)\n",
    "    \n",
    "    naya = cv2.bitwise_and(img1, img1, mask = mask)\n",
    "    \n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"Region of Interest\", naya)\n",
    "    \n",
    "    hand_bg_rm = naya\n",
    "    hand = img1\n",
    "    \n",
    "    # Control Key    \n",
    "    c = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    # Speak the sentence\n",
    "    if len(sentence) > 0 and c == ord('s'):\n",
    "        engine.say(sentence)\n",
    "        engine.runAndWait()\n",
    "    \n",
    "    # Clear the sentence\n",
    "    if c == ord('c') or c == ord('C'):\n",
    "        sentence = \"\"\n",
    "    \n",
    "    # Delete the last character\n",
    "    if c == ord('d') or c == ord('D'):\n",
    "        sentence = sentence[:-1]\n",
    "    \n",
    "    # Put Space between words\n",
    "    if c == ord('m') or c == ord('M'):\n",
    "        sentence += ' '\n",
    "        \n",
    "    # If  valid hand area is cropped    \n",
    "    if hand.shape[0] != 0 and hand.shape[1] != 0:\n",
    "        conf, label = which_letter(hand_bg_rm)\n",
    "    \n",
    "        cv2.putText(frame, label, (90,90), cv2.FONT_HERSHEY_COMPLEX, 3.0 , (0,0,0))\n",
    "        if c == ord('n') or c == ord('N'):\n",
    "            sentence += label\n",
    "        \n",
    "    cv2.putText(frame, sentence, (90, 180), cv2.FONT_HERSHEY_COMPLEX, 3.0, (0,0,0))\n",
    "    cv2.imshow(window_name, frame)\n",
    "    \n",
    "    # If pressed ESC break\n",
    "    if c == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
